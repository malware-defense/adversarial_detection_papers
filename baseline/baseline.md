- Detecting adversarial examples on deep neural networks with mutual information neural estimation (MIAED)
  - On detecting adversarial perturbations (GND)
  - Detecting adversarial samples from artifacts (KD+BU)
  - Characterizing adversarial subspaces using local intrinsic dimensionality (LID)
  - Adversarial and clean data are not twins (SSD)
  - Detecting adversarial image examples in deep neural networks with adaptive noise reduction (TSD)

- A Simple Unsupervised Data Depth-based Method to Detect Adversarial Images
  - Feature squeezing: Detecting adversarial examples in deep neural networks (FS)
  - Magnet: A two-pronged defense against adversarial examples (Magnet)

- EMShepherd: Detecting Adversarial Samples via Side-channel Leakage
  - Detecting adversarial samples with neural network invariant checking. (KDE)
  - Detecting adversarial samples from artifacts. (NIC)
  - Feature squeezing: Detecting adversarial examples in deep neural networks (FS)
  - Magnet: A two-pronged defense against adversarial examples (Magnet)
  
- Adversarial Detection by Latent Style Transformations [image transformation based multi-point defense techniques]
  - Defense-gan:Protecting classifiers against adversarial attacks using generative models ( Defense-GAN)
  - Magnet: a two-pronged defense against adversarial examples (Magnet)
  - Featurized bidirectional gan:Adversarial defense via adversarially learned semantic inference (FBGAN)
  - Detecting adversarial examples via neural fingerprinting (NFP)
  - Detecting adversarial examples through image transformation (RIT)
  
- ViDetecting adversarial examples is (nearly) as hard as classifying them 
  - 
