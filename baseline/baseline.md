- Detecting adversarial examples on deep neural networks with mutual information neural estimation (MIAED)
  - On detecting adversarial perturbations (GND)
  - Detecting adversarial samples from artifacts (KD+BU)
  - Characterizing adversarial subspaces using local intrinsic dimensionality (LID)
  - Adversarial and clean data are not twins (SSD)
  - Detecting adversarial image examples in deep neural networks with adaptive noise reduction (TSD)

- A Simple Unsupervised Data Depth-based Method to Detect Adversarial Images
  - Feature squeezing: Detecting adversarial examples in deep neural networks (FS)
  - Magnet: A two-pronged defense against adversarial examples (Magnet)

- EMShepherd: Detecting Adversarial Samples via Side-channel Leakage
  - Detecting adversarial samples with neural network invariant checking. (KDE)
  - Detecting adversarial samples from artifacts. (NIC)
  - Feature squeezing: Detecting adversarial examples in deep neural networks (FS)
  - Magnet: A two-pronged defense against adversarial examples (Magnet)
  
- Adversarial Detection by Latent Style Transformations [image transformation based multi-point defense techniques]
  - Defense-gan:Protecting classifiers against adversarial attacks using generative models ( Defense-GAN)
  - Magnet: a two-pronged defense against adversarial examples (Magnet)
  - Featurized bidirectional gan:Adversarial defense via adversarially learned semantic inference (FBGAN)
  - Detecting adversarial examples via neural fingerprinting (NFP)
  - Detecting adversarial examples through image transformation (RIT)
  
- ViDetecting adversarial examples is (nearly) as hard as classifying them 
  
- {WaveGuard}: Understanding and mitigating audio adversarial examples [audio domin, attack和defense均是选取本领域的，可借鉴]
  - Isolated and ensemble audio preprocessing methods for detecting adversarial examples against automatic speech recognition
  - Characterizing audio adversarial examples using temporal dependency
  
  - Magnet: a two-pronged defense against adversarial examples
  - Countering adversarial images using input transformations
  - Defensive quantization: When efficiency meets robustness
  - Qusecnets: Quantization based defense mechanism for securing deep neural network against adversarial attacks
  - Detecting adversarial image examples in deep neural networks with adaptive noise reduction


- Attack as Detection: Using Adversarial Attack Methods to Detect Abnormal Examples
  - Detecting adversarial samples from artifacts.
  - Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality
  - Dissector: Input Validation for Deep Learning Applications by Crossing-layer Dissection.
  - Adversarial sample detection for deep neural network through model mutation testing.